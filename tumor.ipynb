{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations:  339 \n",
      "Number of features:  18\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data, meta = arff.loadarff('./dataset/primary-tumor.arff')\n",
    "print(\"Number of observations: \", len(data), \"\\nNumber of features: \", len(data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The tumor dataset contains 339 observations each with 18 features. These variables are all categorical variables. I choose to use parameters to predict the positive and negative of the binary class variable. That is, treating the binary class feature as a response variable, and then there are 17 explanatory variables. The first task is to clean the dataset. For missing values, I took two distinct approaches: 1. removing rows with any missing value and 2. patching the missing values in the dataset. For the patching missing data approach, following a data cleansing convention, I choose to have the missing values replaced by the mode or mean value of the same category. After data cleansing, I will build a logistic regression model to predict the response using necessary explanatory variables. The performance of the model will be evaluated with cross validation(CV), and the results from two data cleansing approaches will be compared against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([b'?', b'fairly', b'poorly', b'well'], dtype='|S6'),\n",
       " array([b'30-59', b'<30', b'>=60'], dtype='|S5'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['degree-of-diffe']), np.unique(data['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colname: age, num. of missing value: 0\n",
      "colname: sex, num. of missing value: 1\n",
      "colname: histologic-type, num. of missing value: 67\n",
      "colname: degree-of-diffe, num. of missing value: 155\n",
      "colname: bone, num. of missing value: 0\n",
      "colname: bone-marrow, num. of missing value: 0\n",
      "colname: lung, num. of missing value: 0\n",
      "colname: pleura, num. of missing value: 0\n",
      "colname: peritoneum, num. of missing value: 0\n",
      "colname: liver, num. of missing value: 0\n",
      "colname: brain, num. of missing value: 0\n",
      "colname: skin, num. of missing value: 1\n",
      "colname: neck, num. of missing value: 0\n",
      "colname: supraclavicular, num. of missing value: 0\n",
      "colname: axillar, num. of missing value: 1\n",
      "colname: mediastinum, num. of missing value: 0\n",
      "colname: abdominal, num. of missing value: 0\n",
      "colname: binaryClass, num. of missing value: 0\n"
     ]
    }
   ],
   "source": [
    "for name, col in df.items():\n",
    "    print(f\"colname: {name}, num. of missing value:\", sum(col == '?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify the rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bad rows: 69\n"
     ]
    }
   ],
   "source": [
    "bad_rows = []\n",
    "for col in ['sex', 'skin', 'axillar', 'histologic-type']:\n",
    "    bad_rows += df.index[df[col] == '?'].tolist()\n",
    "bad_rows = np.unique(bad_rows)\n",
    "print(f\"Number of bad rows: {len(bad_rows)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patch the missing values\n",
    "\n",
    "Looking at the missing values, we can see that the missing values are in the columns `sex`, `histologic-type`, `degree-of-diffe`, `skin`, `axillar`. For `sex`, `skin`, `axillar`, there is only one missing value in each column, so I choose to patch it with the mode value of that column. On the other hand, `degree-of-diffe` has too many missing values, nearly half of the observations. In this case, this column will be removed from the analysis in the next steps. Lastly, for `histologic-type`, I choose to follow the expected occurrence to fill in the values for the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['sex', 'skin', 'axillar']:\n",
    "    df[col] = df[col].replace('?', df[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?' 'adeno' 'anaplastic' 'epidermoid'] [ 67 220   8  44]\n"
     ]
    }
   ],
   "source": [
    "val, counts = np.unique(df['histologic-type'], return_counts=True)\n",
    "print(val, counts)\n",
    "counts = counts[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled value and occurrence:\n",
      "adeno 57\n",
      "anaplastic 2\n",
      "epidermoid 8\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "fills = np.random.choice(val[1:], size=67, p=[counts[0]/sum(counts), counts[1]/sum(counts), counts[2]/sum(counts)])\n",
    "fill_val, fill_counts = np.unique(fills, return_counts=True)\n",
    "print(\"Filled value and occurrence:\")\n",
    "for v, c in zip(fill_val, fill_counts):\n",
    "    print(v, c)\n",
    "for i, idx in enumerate(df[df[\"histologic-type\"] == \"?\"].index):\n",
    "    df['histologic-type'][idx] = fills[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the degree-of-diffe column\n",
    "df = df.drop(columns=['degree-of-diffe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data to numerics and create the design matrix\n",
    "design = pd.get_dummies(df.drop(columns='binaryClass'), dtype=int)\n",
    "response = df['binaryClass'].map({'N': 0, 'P': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_drop = pd.get_dummies(df.drop(bad_rows).drop(columns='binaryClass'), dtype=int)\n",
    "response_drop = df.drop(bad_rows)['binaryClass'].map({'N': 0, 'P': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the logistic regression model\n",
    "\n",
    "Since the response variable is a binary class, it is convenient to build a logistic\n",
    "regression model to predict the response using the exploratory variables. The performance of the model is measured using 5-fold CV.\n",
    "A comparison between removing the rows of the missing values in the table after removing the column `degree-of-diffe` and using imputation to fill the values are performed and discussed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By removing rows with any missing value, the mean accuracy is:  0.8703703703703705\n",
      "By patching the missing values, the mean accuracy is:  0.8435908691834945\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "print(\"By removing rows with any missing value, the mean accuracy is: \", cross_val_score(clf, design_drop, response_drop, cv=5).mean())\n",
    "print(\"By patching the missing values, the mean accuracy is: \", cross_val_score(clf, design, response, cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0636175 , -0.07612299,  0.01276981, -0.31280611,  0.31307042,\n",
       "        -1.40393297,  0.58507355,  0.81912374, -0.25740756,  0.25767187,\n",
       "        -0.1327541 ,  0.13301842,  0.41347863, -0.41321432, -0.30357582,\n",
       "         0.30384013,  0.18991419, -0.18964988, -0.20165245,  0.20191677,\n",
       "        -0.39657215,  0.39683646, -0.82501741,  0.82528172,  1.16425717,\n",
       "        -1.16399286, -0.44311131,  0.44337562,  0.57452116, -0.57425685,\n",
       "        -1.25150799,  1.2517723 ,  0.50728716, -0.50702285]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(design, response)\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and discussion\n",
    "\n",
    "From the analysis above, we can see that the 17 explanatory variables correlate fairly well with the binary class response variable. The 5-fold cross-validation shows a mean accuracy of 0.8436 for the approach with patching the missing values, and 0.8704 for removing the rows with missing values. The removing missing value row approach has a slightly better accuracy, but it might lose some generalities for inferencing with new data because our number of observations is reduced by 69 after removing those missing value rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
